{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels are : [0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data=np.genfromtxt('Outlier.txt',delimiter=',')\n",
    "np.random.shuffle(data); # Since data given is sorted\n",
    "Y=data[:,-1]\n",
    "X=data[:,:-1]\n",
    "#X=np.genfromtxt('X.csv',delimiter=',')\n",
    "#Y=np.genfromtxt('y.csv',delimiter=',')\n",
    "print(\"The labels are : \"+str(np.unique(Y)))  \n",
    "#np.random.shuffle((data['X']),(data['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:  48.66666666666667%\n",
      "Layer 1 : \n",
      "Weights: [[ 0.086537   -0.04979254]\n",
      " [ 0.10043184 -0.01815081]\n",
      " [ 0.05416694  0.03972151]\n",
      " [ 0.01805425 -0.01331753]\n",
      " [-0.01518123  0.09416107]\n",
      " [-0.1171934   0.06890044]\n",
      " [-0.10179049 -0.00505017]\n",
      " [-0.02029753 -0.00242861]]\n",
      "Bias: [ 0.09060564 -0.11454867 -0.06007048 -0.10930875  0.04416869  0.00352217\n",
      " -0.03364255  0.15134893]\n",
      "Layer 2 : \n",
      "Weights: [[ 0.05589674  0.02553055  0.15033471  0.07332912  0.19178767  0.22297472\n",
      "   0.16632176  0.132208  ]\n",
      " [ 0.12946943  0.06421673  0.08957863  0.05167243  0.09756241  0.0280619\n",
      "   0.20483958  0.2529791 ]\n",
      " [ 0.12948876  0.01960773  0.20880433  0.07965086  0.2188853   0.22886332\n",
      "   0.12099751  0.06817129]\n",
      " [ 0.0125299   0.00481911  0.0610238  -0.00170942  0.06540501  0.20789291\n",
      "   0.09268288  0.12751164]\n",
      " [ 0.09780716  0.06052978  0.02494451  0.19855127  0.22479232  0.1663777\n",
      "   0.16739157  0.09830604]\n",
      " [ 0.04746678  0.01903952  0.22080458  0.10529419  0.12838702  0.2397154\n",
      "   0.20151119  0.18062489]\n",
      " [ 0.1307563   0.09183289  0.00291844  0.01190558  0.12576067  0.12183332\n",
      "   0.05000122  0.16659241]\n",
      " [-0.00443049  0.09849215  0.00996456  0.05408316 -0.02173721  0.07096692\n",
      "   0.11351258  0.18597432]]\n",
      "Bias: [0.19110289 0.19835292 0.24894135 0.11179485 0.24578636 0.36915199\n",
      " 0.34291454 0.09598189]\n",
      "Layer 3 : \n",
      "Weights: [[ 0.48817829  0.5240034   0.57365363  0.4273025   0.6784158   0.57434945\n",
      "   0.48887966  0.55231893]\n",
      " [-0.59096388 -0.43736406 -0.57684268 -0.41055822 -0.48709576 -0.65528522\n",
      "  -0.63010756 -0.49291738]\n",
      " [ 0.20506283  0.2746653   0.38062557  0.1585755   0.34829291  0.20918945\n",
      "   0.40327773  0.22731666]\n",
      " [ 0.47769769  0.50147429  0.55472119  0.31911125  0.41968468  0.35721089\n",
      "   0.34056136  0.2715121 ]\n",
      " [ 0.07198177  0.1724703   0.10347028  0.18980737  0.12941882  0.21382527\n",
      "   0.19178434  0.03391716]\n",
      " [-0.16231418 -0.33924279 -0.19674801 -0.31992875 -0.26806056 -0.36866426\n",
      "  -0.27099043 -0.12366444]\n",
      " [ 0.23554561  0.39163132  0.36945332  0.28804433  0.40607561  0.36709496\n",
      "   0.23739601  0.21553219]\n",
      " [ 0.53304136  0.52190293  0.32804467  0.48860594  0.39226835  0.50130451\n",
      "   0.35231746  0.35088043]]\n",
      "Bias: [ 0.90970327 -0.81980204  0.51397949  0.86964603  0.35696517 -0.40050967\n",
      "  0.43509291  0.83122354]\n",
      "Layer 4 : \n",
      "Weights: [[ 1.07679749e+00  7.88886697e-01  1.14330292e+00  9.96832798e-01\n",
      "   1.13656875e+00  1.01576851e+00  1.01564770e+00  1.12530085e+00]\n",
      " [-8.28208274e-01 -2.31829108e-01 -7.28992920e-01 -6.80781126e-01\n",
      "  -7.49188689e-01 -3.80689058e-01 -6.99468453e-01 -6.86405632e-01]\n",
      " [-1.06796139e+00 -6.60879918e-01 -1.06722726e+00 -1.07280045e+00\n",
      "  -8.91945571e-01 -8.56702061e-01 -8.77983311e-01 -9.69051868e-01]\n",
      " [ 6.91947395e-01  3.34150239e-01  7.53379631e-01  6.46654641e-01\n",
      "   6.58824103e-01  5.13674643e-01  6.22116317e-01  6.66032521e-01]\n",
      " [ 6.95735941e-02 -1.08755183e-01  2.70351039e-02 -9.03577835e-02\n",
      "  -6.60446295e-02  6.63972012e-02 -6.73087144e-02 -3.63060992e-02]\n",
      " [ 1.19933427e-01 -5.59681358e-02 -5.66845960e-02  9.91107024e-02\n",
      "  -2.72690359e-02 -1.02178186e-01  6.05841638e-02  4.13940138e-02]\n",
      " [-5.67959193e-02  8.63480623e-02 -3.82671949e-02 -8.10290795e-02\n",
      "  -2.64620485e-02 -1.04582936e-03 -5.08675882e-02 -7.70558623e-02]\n",
      " [-2.67813174e-02 -4.70854385e-02 -7.16976619e-03 -5.48250194e-03\n",
      "   2.96945603e-02 -7.00957637e-02 -3.45012896e-02  1.24893209e-02]]\n",
      "Bias: [ 1.75193257 -1.03908758 -1.46936639  0.90228167  0.03031945  0.08790169\n",
      "  0.04414579 -0.0568873 ]\n",
      "Layer 5 : \n",
      "Weights: [[-0.11041902 -0.07868626  0.10954119 -0.03211334 -0.06795246  0.11941232\n",
      "  -0.07785106  0.0035189 ]\n",
      " [-0.11337331 -0.00776498  0.03386054  0.06026222 -0.03667195  0.02036293\n",
      "   0.02469752 -0.01195496]\n",
      " [-0.10488887  0.02364842  0.06932133 -0.08220642 -0.05111623 -0.1098926\n",
      "   0.0966952  -0.07893316]\n",
      " [-0.02158184  0.01812708  0.00643587 -0.01150857  0.07644445 -0.0497765\n",
      "  -0.09891968  0.03726296]]\n",
      "Bias: [ 0.04553936  0.02468826 -0.06463147  0.09187894]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import NNClassifier as NNC\n",
    "def normalise(Xin):\n",
    "        return (Xin-np.mean(Xin,axis=0))/np.std(Xin,axis=0)    # NORMALISING FEATURES\n",
    "\n",
    "sz=X.shape[0]\n",
    "X=normalise(X)   #normalising X\n",
    "# separation of training set and test set\n",
    "test_sz=sz//4  \n",
    "tr_sz=sz-test_sz   \n",
    "layer_sz=[8,8,8,8]\n",
    "train=NNC.NNClassifier()\n",
    "train.set(X[:tr_sz-1,:],Y[:tr_sz-1],layer_sz)\n",
    "test=NNC.NNClassifier()\n",
    "test.set(X[tr_sz:,:],Y[tr_sz:],layer_sz)\n",
    "train.miniGradientDescent(5,LAMBDA=0,alpha=0.1,iter=2000)\n",
    "print(\"Accuracy on test set:  \"+str(train.accuracy(test))+\"%\")\n",
    "train.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set (By sklearn) : 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(activation='relu',batch_size=5,hidden_layer_sizes=(8,8,8,8))\n",
    "clf.fit(X[:tr_sz-1,:],Y[:tr_sz-1])\n",
    "acc=(sum(clf.predict(X[tr_sz:,:])==Y[tr_sz:])/test_sz)*100\n",
    "print(\"Accuracy on test set (By sklearn) : \"+str(acc)+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

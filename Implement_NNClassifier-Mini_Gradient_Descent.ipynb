{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels are : [0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data=np.genfromtxt('Outlier.txt',delimiter=',')\n",
    "np.random.shuffle(data); # Since data given is sorted\n",
    "Y=data[:,-1]\n",
    "X=data[:,:-1]\n",
    "#X=np.genfromtxt('X.csv',delimiter=',')\n",
    "#Y=np.genfromtxt('y.csv',delimiter=',')\n",
    "print(\"The labels are : \"+str(np.unique(Y)))  \n",
    "#np.random.shuffle((data['X']),(data['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:  47.333333333333336%\n",
      "Layer 1 : \n",
      "Weights: [[ 0.06599182 -0.01394198]\n",
      " [-0.02447147 -0.02446525]\n",
      " [-0.05187802  0.08190996]\n",
      " [ 0.0311757   0.10121361]\n",
      " [ 0.16784673  0.03808   ]\n",
      " [-0.02975174  0.0517551 ]\n",
      " [ 0.0481959   0.11056426]\n",
      " [ 0.14897456  0.06571253]]\n",
      "Bias: [-0.01029426 -0.01918179  0.02143439  0.03238464  0.08614615  0.0680353\n",
      "  0.05690541  0.12859909]\n",
      "Layer 2 : \n",
      "Weights: [[ 0.18936289  0.10897663  0.04365365  0.08502444  0.17872955  0.2078296\n",
      "   0.06069437  0.01500171]\n",
      " [ 0.17471827  0.04060717  0.14797872  0.22690968  0.25047666  0.05855422\n",
      "   0.20707758  0.18564739]\n",
      " [ 0.09964351  0.214207    0.10705655  0.14651334  0.16074219  0.10796649\n",
      "   0.2174634   0.13774624]\n",
      " [ 0.11420379  0.08060354  0.16820225  0.12285148  0.18327618  0.03809001\n",
      "   0.02138543  0.20483739]\n",
      " [ 0.03203832  0.10655138  0.06865279 -0.0044705   0.16096822  0.0813754\n",
      "   0.20983935  0.13769418]\n",
      " [ 0.17585232  0.01188734  0.16659595  0.11482635  0.12398618  0.15715187\n",
      "   0.21625927  0.15214677]\n",
      " [ 0.06279618  0.00560808  0.1718569   0.04712331  0.15166088  0.2136618\n",
      "   0.0700884   0.03868151]\n",
      " [ 0.13804438  0.16230894  0.21488793  0.25156556  0.18173339  0.24859958\n",
      "   0.18693116  0.19602848]]\n",
      "Bias: [0.31631487 0.18766095 0.2024853  0.35222783 0.17141621 0.20328079\n",
      " 0.14341259 0.40997956]\n",
      "Layer 3 : \n",
      "Weights: [[ 0.22573495  0.24782599  0.2685504   0.41136474  0.20192888  0.3516696\n",
      "   0.36648682  0.27337965]\n",
      " [-0.47656104 -0.5351878  -0.57267389 -0.55025999 -0.57820618 -0.51166933\n",
      "  -0.44235948 -0.57679205]\n",
      " [ 0.3306578   0.3300991   0.35054541  0.19906732  0.21911609  0.37611018\n",
      "   0.24902364  0.31478706]\n",
      " [ 0.53200332  0.55447127  0.63786261  0.61893686  0.40680514  0.43730101\n",
      "   0.37791868  0.70503911]\n",
      " [ 0.35956628  0.45479086  0.33054351  0.38825328  0.35027857  0.49785846\n",
      "   0.45865611  0.51666896]\n",
      " [-0.38142871 -0.47212173 -0.50181823 -0.41807663 -0.28602245 -0.39028658\n",
      "  -0.4711835  -0.49722503]\n",
      " [-0.36087362 -0.19762575 -0.39733641 -0.36839768 -0.24416267 -0.38474281\n",
      "  -0.152693   -0.42487101]\n",
      " [ 0.29320837  0.43045904  0.2414738   0.2225156   0.3469764   0.29716901\n",
      "   0.33378077  0.46371494]]\n",
      "Bias: [ 0.6408219  -0.8150776   0.52207309  0.95464046  0.80701445 -0.61766728\n",
      " -0.42950866  0.63447519]\n",
      "Layer 4 : \n",
      "Weights: [[-0.93441314 -0.62588515 -0.91611746 -1.01881642 -0.94756569 -0.65212285\n",
      "  -0.74047402 -0.86512268]\n",
      " [ 0.49785194  0.18028618  0.70268613  0.5751398   0.64972339  0.21506699\n",
      "   0.28687756  0.56027204]\n",
      " [-0.96617224 -0.59447403 -1.09601829 -1.03253994 -1.20160677 -0.89070606\n",
      "  -0.77921267 -0.99820657]\n",
      " [-0.98220917 -0.74142868 -1.22203695 -1.07523626 -1.11093892 -0.83194572\n",
      "  -0.9572274  -1.2591167 ]\n",
      " [ 0.11685989 -0.05496563  0.01602977  0.09150507  0.09509406 -0.11194152\n",
      "  -0.01757996  0.01895556]\n",
      " [-0.08131721 -0.09198625  0.06411155 -0.08488018  0.03642383 -0.04960975\n",
      "  -0.08588974 -0.07586481]\n",
      " [-0.07083875 -0.02147342 -0.08709803  0.08846983 -0.04827832  0.06869318\n",
      "  -0.06990776  0.00542752]\n",
      " [-0.09257937 -0.10585419 -0.00987274  0.04816648 -0.10159712  0.02023716\n",
      "   0.04411603  0.0544021 ]]\n",
      "Bias: [-1.36499607  0.89716854 -1.81239815 -1.86103563  0.02513301 -0.02302366\n",
      "  0.08397336  0.08703031]\n",
      "Layer 5 : \n",
      "Weights: [[ 0.07726323 -0.04448848  0.02941914 -0.00193922  0.02038689 -0.0429912\n",
      "  -0.06280102  0.03509998]\n",
      " [ 0.01134904 -0.03419295  0.0899056   0.11271812 -0.08817424 -0.05271689\n",
      "  -0.07927593  0.05406885]\n",
      " [ 0.04037366  0.02889455  0.00597153  0.04857465 -0.09107454 -0.02673809\n",
      "   0.02584222 -0.10493069]\n",
      " [-0.10348011  0.02884537 -0.00452741 -0.06967906  0.11074309  0.11276635\n",
      "  -0.01103865 -0.10856924]]\n",
      "Bias: [ 0.0614579   0.03987593 -0.11447546  0.08819499]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import NNClassifier as NNC\n",
    "def normalise(Xin):\n",
    "        return (Xin-np.mean(Xin,axis=0))/np.std(Xin,axis=0)    # NORMALISING FEATURES\n",
    "\n",
    "sz=X.shape[0]\n",
    "X=normalise(X)   #normalising X\n",
    "# separation of training set and test set\n",
    "test_sz=sz//4  \n",
    "tr_sz=sz-test_sz   \n",
    "layer_sz=[8,8,8,8]\n",
    "train=NNC.NNClassifier()\n",
    "train.set(X[:tr_sz-1,:],Y[:tr_sz-1],layer_sz)\n",
    "test=NNC.NNClassifier()\n",
    "test.set(X[tr_sz:,:],Y[tr_sz:],layer_sz)\n",
    "train.miniGradientDescent(10,LAMBDA=0,alpha=0.1,iter=1000)\n",
    "print(\"Accuracy on test set:  \"+str(train.accuracy(test))+\"%\")\n",
    "train.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set (By sklearn) : 94.66666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(activation='relu',batch_size='auto',hidden_layer_sizes=(8,8,8,8))\n",
    "clf.fit(X[:tr_sz-1,:],Y[:tr_sz-1])\n",
    "acc=(sum(clf.predict(X[tr_sz:,:])==Y[tr_sz:])/test_sz)*100\n",
    "print(\"Accuracy on test set (By sklearn) : \"+str(acc)+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
